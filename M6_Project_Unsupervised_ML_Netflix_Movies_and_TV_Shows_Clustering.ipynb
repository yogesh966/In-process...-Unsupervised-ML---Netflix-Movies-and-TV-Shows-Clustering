{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogesh966/In-process...-Unsupervised-ML---Netflix-Movies-and-TV-Shows-Clustering/blob/main/M6_Project_Unsupervised_ML_Netflix_Movies_and_TV_Shows_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -Unsupervised ML - Netflix Movies and TV Shows Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised ML - Netflix Movies and TV Shows Clustering\n",
        "##### **Contribution**    - Individual\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine. In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**\n",
        "https://github.com/yogesh966/In-process...-Unsupervised-ML---Netflix-Movies-and-TV-Shows-Clustering"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n",
        "Netflix is one of the world's leading entertainment services with over 260 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Netflix is the most-subscribed video on demand streaming media service, with 260.28 million paid memberships in more than 190 countries as of January 2024.\n",
        "\n",
        "It is crucial that they effectively cluster the shows that are hosted on their platform in order to enhance the user experience, thereby preventing subscriber churn.\n",
        "\n",
        "We will be able to understand the shows that are similar to and different from one another by creating clusters, which may be leveraged to offer the consumers personalized show suggestions depending on their preferences.\n",
        "\n",
        "The goal of this project is to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other."
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Objective**\n",
        "In this project, you are required to do:\n",
        "\n",
        "1. Exploratory Data Analysis\n",
        "\n",
        "2. Understanding what type content is available in different countries\n",
        "\n",
        "3. If Netflix has been increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "4. Clustering similar content by matching text-based features\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime as dt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "#import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import PCA\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "string.punctuation\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import scipy.cluster.hierarchy as shc\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "%matplotlib inline\n",
        "sns.set()"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data='/content/drive/My Drive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv'\n",
        "\n",
        "#Read the data\n",
        "original_df=pd.read_csv(data)\n",
        "df=original_df.copy()\n",
        "df"
      ],
      "metadata": {
        "id": "vckOZ6tZ4qb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information\n",
        "1. show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "2. type : Identifier - A Movie or TV Show\n",
        "\n",
        "3. title : Title of the Movie / Tv Show\n",
        "\n",
        "4. director : Director of the Movie\n",
        "\n",
        "5. cast : Actors involved in the movie / show\n",
        "\n",
        "6. country : Country where the movie / show was produced\n",
        "\n",
        "7. date_added : Date it was added on Netflix\n",
        "\n",
        "8. release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "9. rating : TV Rating of the movie / show\n",
        "\n",
        "10. duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "11. listed_in : Genre\n",
        "\n",
        "12. description: The Summary description"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(df[df.duplicated()].sum())\n",
        "\n",
        "print(f\"No of dduplicate values : {df[df.duplicated()].sum().sum()}\")"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hence,there is no any row containing duplicate values.**"
      ],
      "metadata": {
        "id": "L6SctKywqm0P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum().reset_index().rename(columns={'index':\"column\", 0:\"count\"}).sort_values(by='count',ascending=False)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "nYPMiAxut1cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "#Columns with null values\n",
        "null_col=df.columns[df.isnull().any()]\n",
        "null_col\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualize null values count\n",
        "\n",
        "plt.bar(null_col,df[null_col].isnull().sum())\n",
        "plt.title(\"Missing/null value Count\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"No of missing values\")\n"
      ],
      "metadata": {
        "id": "DiBkU95bxte4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "2. type : Identifier - A Movie or TV Show\n",
        "\n",
        "3. title : Title of the Movie / Tv Show\n",
        "\n",
        "4. director : Director of the Movie\n",
        "\n",
        "5. cast : Actors involved in the movie / show\n",
        "\n",
        "6. country : Country where the movie / show was produced\n",
        "\n",
        "7. date_added : Date it was added on Netflix\n",
        "\n",
        "8. release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "9. rating : TV Rating of the movie / show\n",
        "\n",
        "10. duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "11. listed_in : Genre\n",
        "\n",
        "12. description: The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling the missing values"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[df.isnull().any()]"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#filling the null values with appropriate value\n",
        "df[['director','cast','country']] = df[['director','cast','country']].fillna('Unknown')\n",
        "df['rating'] = df['rating'].fillna(df['rating'].mode()[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "Rqf0Go4Y3yFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "NYDCtErY3yIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "nvvcD-tH3yRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Country, listed_in:**"
      ],
      "metadata": {
        "id": "kISvsYKY6lDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top countries\n",
        "df.country.value_counts()"
      ],
      "metadata": {
        "id": "7eIZU7cX6laT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Genre of the shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "AA7sJEvR6l_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There are some movies / TV shows that were filmed in multiple countries, have multiple genres associated with it.\n",
        "\n",
        "To simplify the analysis, let's consider only the primary country where that respective movie / TV show was filmed.\n",
        "\n",
        "Also, let's consider only the primary genre of the respective movie / TV show."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Choosing the primary country and primary genre to simplify the analysis\n",
        "df['country'] = df['country'].apply(lambda x: x.split(',')[0])\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x: x.split(',')[0])\n"
      ],
      "metadata": {
        "id": "4rMj31wv8vzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#contry in which a movie was produced\n",
        "df.country.value_counts()"
      ],
      "metadata": {
        "id": "0YQRZZtK9Dud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# genre of shows\n",
        "df.listed_in.value_counts()"
      ],
      "metadata": {
        "id": "-z_q4Mh-9OlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Typecasting 'duration' from string to integer**"
      ],
      "metadata": {
        "id": "1l1O_UwM9wCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the duration column, and changing the datatype to integer\n",
        "\n",
        "df['duration'] = df['duration'].apply(lambda x : int(x.split()[0]))\n"
      ],
      "metadata": {
        "id": "VVvdW8w490YO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of seasons for tv shows\n",
        "df[df['type']=='TV Show'].duration.value_counts()\n"
      ],
      "metadata": {
        "id": "5r16WA4191B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie length in minutes\n",
        "df[df['type'] == 'Movie'].duration.unique()"
      ],
      "metadata": {
        "id": "_gN7A9-891E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datatype of duration\n",
        "df.duration.dtype"
      ],
      "metadata": {
        "id": "HFDuMlC291H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Successfully converted the datatype of duration column to int.***\n",
        "\n"
      ],
      "metadata": {
        "id": "NF7_Rz4hDvhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Typecasting 'date_added' from string to datetime:**\n"
      ],
      "metadata": {
        "id": "lUcLPQv8D8vp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.date_added.dtype"
      ],
      "metadata": {
        "id": "_Mm3WonFFic7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Typecasting 'date_added' from string to datetime\n",
        "\n",
        "df['date_added'] = pd.to_datetime(df['date_added'].str.strip(), format=\"%B %d, %Y\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3OQiYCCa91Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.date_added.min(),df.date_added.max()"
      ],
      "metadata": {
        "id": "_egC9UD491Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***The shows were added on Netflix between 1st January 2008 and 16th January 2021.***"
      ],
      "metadata": {
        "id": "nf1d8UtaKj0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding new attributes/columns:**"
      ],
      "metadata": {
        "id": "9cNChyOULIii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding new attributes month and year of date added\n",
        "df['month_added'] = df['date_added'].dt.month\n",
        "df['year_added'] = df['date_added'].dt.year"
      ],
      "metadata": {
        "id": "0CHB1Oom91Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rating:**\n"
      ],
      "metadata": {
        "id": "aZTJ9w45YQH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Age ratings for shows in the dataset**"
      ],
      "metadata": {
        "id": "Mn3X1T3OYgd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "sns.countplot(x='rating', data=df)"
      ],
      "metadata": {
        "id": "gfna_SgeYb3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ***Highest number of shows on Netflix are rated by TV-MA, followed by TV-14 and TV-PG.***\n",
        "\n"
      ],
      "metadata": {
        "id": "qoYDzFg5Ytaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Age ratings\n",
        "df.rating.unique()"
      ],
      "metadata": {
        "id": "o4M0TZpCY3kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the values in the rating column\n",
        "rating_map = {'TV-MA':'Adults',\n",
        "              'R':'Adults',\n",
        "              'PG-13':'Teens',\n",
        "              'TV-14':'Young Adults',\n",
        "              'TV-PG':'Older Kids',\n",
        "              'NR':'Adults',\n",
        "              'TV-G':'Kids',\n",
        "              'TV-Y':'Kids',\n",
        "              'TV-Y7':'Older Kids',\n",
        "              'PG':'Older Kids',\n",
        "              'G':'Kids',\n",
        "              'NC-17':'Adults',\n",
        "              'TV-Y7-FV':'Older Kids',\n",
        "              'UR':'Adults'}\n",
        "\n",
        "df['rating'].replace(rating_map, inplace = True)\n",
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "G9t77rOSY6AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Age ratings for shows in the dataset**"
      ],
      "metadata": {
        "id": "KCWaD-H7ZFZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.countplot(x='rating',data=df)"
      ],
      "metadata": {
        "id": "gQNfL7vbZEqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most shows on Netflix are produced for adult audience. Followed by young adults, older kids and kids. Netflix has the least number of shows that are specifically produced for teenagers than other age groups.\n",
        "**bold text**\n"
      ],
      "metadata": {
        "id": "6li1Z-FpZMuJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory data analysis**"
      ],
      "metadata": {
        "id": "Gj2nGnTMOeRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Exploratory Data Analysis (EDA) is an approach to analyzing datasets to summarize their main characteristics, often employing visual methods. Its primary goal is to gain insights into the data, identify patterns, trends, anomalies, and relationships between variables. EDA helps researchers or analysts understand the underlying structure of the data and formulate hypotheses for further investigation."
      ],
      "metadata": {
        "id": "MXOiWz0OOIeD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Univariate analysis**"
      ],
      "metadata": {
        "id": "5ypYFgmWPjtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Involves analyzing a single variable at a time to understand its distribution, central tendency, dispersion, and other summary statistics.\n",
        "\n"
      ],
      "metadata": {
        "id": "XbkdBi2wPtlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Number of Movies and TV Shows in the dataset :**"
      ],
      "metadata": {
        "id": "ankaotpNQmKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "df.type.value_counts().plot(kind='pie',autopct='%1.2f%%')\n",
        "plt.ylabel('')\n",
        "plt.title('Movies and TV Shows in the dataset')"
      ],
      "metadata": {
        "id": "8-gpFWbl91qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.Top 10 directors in the dataset:**"
      ],
      "metadata": {
        "id": "gBUure_eQ4pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 directors by number of shows directed')"
      ],
      "metadata": {
        "id": "yUY35ll091tU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Raul Campos and Jan Suter together have directed 18 movies / TV shows, higher than anyone in the dataset.***"
      ],
      "metadata": {
        "id": "agmLshf-SZTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.Top 10 countries with the highest number movies / TV shows in the dataset**"
      ],
      "metadata": {
        "id": "np8f2-0rEJHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['country']=='Unknown')].country.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title(' Top 10 countries with the highest number of shows')\n"
      ],
      "metadata": {
        "id": "Of0qGSwW91yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The United States boasts the highest count of movies and TV shows, with India and the UK following closely behind.***"
      ],
      "metadata": {
        "id": "KE9T7V-0Eclq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#% share of movies / tv shows by top 3 countries\n",
        "df.country.value_counts().nlargest(3).sum()/len(df)*100"
      ],
      "metadata": {
        "id": "OznlZqef9117"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#% share of movies / tv shows by top 10 countries\n",
        "df.country.value_counts().nlargest(10).sum()/len(df)*100\n"
      ],
      "metadata": {
        "id": "5MS_XpOuGMJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The top three countries collectively contribute to approximately 56% of all movies and TV shows within the dataset, while this proportion escalates to around 78% for the top ten countries.***"
      ],
      "metadata": {
        "id": "-3jf6zYpGWth"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**4.Visualizing the year in which the movie / tv show was released**"
      ],
      "metadata": {
        "id": "yw2V1T0NGdQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['release_year'])\n",
        "plt.title('distribution by released year')"
      ],
      "metadata": {
        "id": "SnL8buEWGb4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The histogram illustrates the distribution of movie and TV show release years, with a noticeable increase in the number of releases after 2000. Peaks indicate periods of higher production or favored eras, while gaps may suggest shifts in content creation or dataset coverage. Understanding these patterns aids in strategic content planning and audience targeting for platforms like Netflix.***"
      ],
      "metadata": {
        "id": "o_2gOFprG0OK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5.Top 10 genres**"
      ],
      "metadata": {
        "id": "LDWyWcM8HBh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "df.listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('top 10 genres')\n"
      ],
      "metadata": {
        "id": "_HPtnrj9HCZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %Share of top 3 genres\n",
        "df.listed_in.value_counts().nlargest(3).sum()/len(df)*100\n",
        "\n"
      ],
      "metadata": {
        "id": "YHP8arKkHDFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %Share of top 10 genres\n",
        "df.listed_in.value_counts().nlargest(10).sum()/len(df)*100"
      ],
      "metadata": {
        "id": "BqX3cZnFHDvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The visualization depicts the top 10 genres based on their frequency within the dataset. Notably, dramas emerge as the most prevalent genre, closely followed by comedies and documentaries. Collectively, these three genres constitute approximately 41% of all movies and TV shows in the dataset. Furthermore, the dominance of these genres becomes even more pronounced among the top 10, encompassing around 82% of the total content. This highlights a clear preference for these genres among viewers, underscoring their significance in content consumption trends.***"
      ],
      "metadata": {
        "id": "G9P1ruTAHEFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**6.Number of shows on Netflix for different age groups.**"
      ],
      "metadata": {
        "id": "6brOUKLdJOQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df.rating.value_counts().plot(kind='barh')\n",
        "plt.title('Number of shows on Netflix for different age groups')"
      ],
      "metadata": {
        "id": "dHaK4Y93HEaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***The majority of the shows on Netflix are catered to the needs of adult and young adult population.***"
      ],
      "metadata": {
        "id": "xU9gTEOsLA5g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Bivariate analysis**"
      ],
      "metadata": {
        "id": "WoKxk1C9LbTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focuses on analyzing the relationship between two variables to uncover patterns, correlations, or associations."
      ],
      "metadata": {
        "id": "KueQIQNzLbFa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.Number of movies and TV shows added over the years**"
      ],
      "metadata": {
        "id": "oGqYFhyhLbB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "p=sns.countplot(x='year_added', data=df, hue='type')\n",
        "plt.title('Number of movies and tv shows added over the years')\n",
        "plt.xlabel('')\n",
        "for i in p.patches:\n",
        "  p.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n"
      ],
      "metadata": {
        "id": "Dsozt-YHL9d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Over the years, Netflix has maintained a consistent emphasis on expanding its library of shows on its platform. While there was a decline in the number of movies added in 2020, a similar trend was not observed in the addition of TV shows during the same period. This might signal that Netflix is increasingly concentrating on introducing more TV series to its platform rather than movies.***"
      ],
      "metadata": {
        "id": "DltqbZ1OL_OS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.Seasons in each TV show**"
      ],
      "metadata": {
        "id": "3EUxbRe1L_H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,5))\n",
        "p = sns.countplot(x='duration', data=df[df['type']=='TV Show'])\n",
        "plt.title('Number of seasons per TV show distribution')\n",
        "for i in p.patches:\n",
        "  p.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
        "\n"
      ],
      "metadata": {
        "id": "JLR0aLj7NX6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# % of tv shows with just 1 season\n",
        "len(df[(df['type']== 'TV Show') & (df['duration']==1)]) / len(df[df['type']=='TV Show'])*100\n"
      ],
      "metadata": {
        "id": "Heo5SM1tL9zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The TV series in the dataset range up to 16 seasons, yet the majority of them consist of only one season. This observation could imply that most TV shows are relatively new, with potential for additional seasons in the future. Additionally, there are very few TV shows with more than 8 seasons.***"
      ],
      "metadata": {
        "id": "66lsrOIML_EY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.length of movie analysis**"
      ],
      "metadata": {
        "id": "TKfTTlLeL_ug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(x='duration',data=df[df['type']=='Movie'])\n",
        "plt.title(\"Movie duration distribution\")"
      ],
      "metadata": {
        "id": "KMJ4x7s4L98F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie statistics\n",
        "df[df['type']== 'Movie'].duration.describe()"
      ],
      "metadata": {
        "id": "yizl9_30L9_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The duration of a movie typically spans from 3 minutes to 312 minutes, exhibiting an almost normal distribution.***"
      ],
      "metadata": {
        "id": "9H8UVpsQKwrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Average movie length over the years**"
      ],
      "metadata": {
        "id": "T-0mSztBLC9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='Movie'].groupby('release_year').duration.mean().plot(kind='line')\n",
        "plt.title('Average movie length over the years')\n",
        "plt.ylabel('Length of movie in minutes')\n",
        "plt.xlabel('Year')\n"
      ],
      "metadata": {
        "id": "tqkeR2P0L-Es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Movie release year statistics\n",
        "df[df['type']== 'Movie'].release_year.describe()"
      ],
      "metadata": {
        "id": "he9x2uGZMM7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Netflix offers a diverse selection of movies, spanning from classics dating back to 1942 to contemporary releases. Interestingly, films from the 1940s tend to have relatively shorter durations, while those from the 1960s boast the longest average lengths. Notably, there has been a consistent decrease in the average movie length since the 2000s.***"
      ],
      "metadata": {
        "id": "AOB4eKYGMLtT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.Top 10 genre for movies**"
      ],
      "metadata": {
        "id": "3t9_H3BwMLLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='Movie'].listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 genres for movies')\n"
      ],
      "metadata": {
        "id": "mY8e9rzpMLb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Dramas, comedies, and documentaries stand out as the most favored genres among Netflix's movie collection, reflecting their widespread appeal and popularity among viewers. Whether audiences seek gripping narratives, lighthearted entertainment, or thought-provoking insights, these genres offer a diverse range of cinematic experiences to suit varied tastes and preferences on the streaming platform.***"
      ],
      "metadata": {
        "id": "5hrQreVgMKl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6.Top 10 genre for tv shows**"
      ],
      "metadata": {
        "id": "m-cuSpEtMKAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[df['type']=='TV Show'].listed_in.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 genres for TV Shows')\n"
      ],
      "metadata": {
        "id": "326-yr3OMKUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***International, crime, and kids' genres prominently feature among the most sought-after categories for TV shows on Netflix, resonating strongly with viewers across diverse demographics. From gripping international dramas to thrilling crime series and engaging content tailored for younger audiences, these genres offer a captivating array of viewing options that cater to a wide spectrum of preferences and interests on the streaming platform.***"
      ],
      "metadata": {
        "id": "l32aJZPCNgKa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7.Top 10 movie directors**"
      ],
      "metadata": {
        "id": "B6ZiIfg1Nx_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10 movie directors\n",
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='Movie')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 movie directors')"
      ],
      "metadata": {
        "id": "j_-m1eT-MK5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Raul Campos and Jan Suter hold the record for co-directing a remarkable total of 18 movies together, surpassing any other duo in this aspect. Following closely behind are Marcus Roboy, Jay Karas, and Cathy Garcia-Molina.***"
      ],
      "metadata": {
        "id": "QuHbI8XWNg1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8.Top 10 TV show directors**"
      ],
      "metadata": {
        "id": "GbCfpoBpOerb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['director']=='Unknown') & (df['type']=='TV Show')].director.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Top 10 TV show directors')"
      ],
      "metadata": {
        "id": "p5qtDEouMJsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Alastair Fothergill leads with the distinction of directing three TV shows, marking the highest count among all directors. Additionally, only a select group of six directors have helmed more than a single television show.***"
      ],
      "metadata": {
        "id": "CSkWu4MPMJYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **9.Top 10 actors for movies**"
      ],
      "metadata": {
        "id": "dyAD2wm2O2Fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "df[~(df['cast']=='Unknown') & (df['type']=='Movie')].cast.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of movies')"
      ],
      "metadata": {
        "id": "DCyKVV6aMJFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Samuel West boasts an impressive presence in 10 movies, securing the top spot, closely followed by Jeff Dunham, who has graced the screen in 7 films.***"
      ],
      "metadata": {
        "id": "CwGNnCcIMIxZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **10.Top 10 actors for TV shows**\n",
        "\n"
      ],
      "metadata": {
        "id": "0OfyYi6YQDbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "df[~(df['cast']=='Unknown') & (df['type']=='TV Show')].cast.value_counts().nlargest(10).plot(kind='barh')\n",
        "plt.title('Actors who have appeared in highest number of TV shows')"
      ],
      "metadata": {
        "id": "JLTWQ0xoMIY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***David Attenborough has appeared in 13 TV shows, followed by Michela Luci, Jamie Watson, Anna Claire Bartlam, Dante Zee, Eric Peterson with 4 TV shows.***"
      ],
      "metadata": {
        "id": "EgKnzmk6MIAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building a wordcloud for the movie descriptions**"
      ],
      "metadata": {
        "id": "oJMHbalmTQlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the cooment_words which include all words in the description section in paragraph format.\n",
        "comment_words = ''\n",
        "stopwords = set(STOPWORDS)\n",
        "# iterate through the csv file\n",
        "for val in df.description.values:\n",
        "   # typecaste each val to string\n",
        "    val = str(val)\n",
        "\n",
        "    # split the value\n",
        "    tokens = val.split()\n",
        "    for i in range(len(tokens)):\n",
        "        tokens[i] = tokens[i].lower()\n",
        "\n",
        "\n",
        "    comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "comment_words\n"
      ],
      "metadata": {
        "id": "npzyNk2vMHj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a wordcloud\n",
        "wordcloud= WordCloud(width=1200, height=700,\n",
        "                     background_color='white',\n",
        "                     stopwords=stopwords,\n",
        "                     min_font_size=10).generate(comment_words)\n"
      ],
      "metadata": {
        "id": "CN1IQHSnZdht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the WordCloud image\n",
        "plt.figure(figsize = (10,5), facecolor = None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "LAxqZKqZaT80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***A collection of significant keywords commonly found in Netflix show descriptions, ideal for generating a word cloud, includes: life, family, new, love, young, world, group, death, man, woman, murder, son, girl, documentary, and secret.***"
      ],
      "metadata": {
        "id": "BzpG7gAMZVxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing**"
      ],
      "metadata": {
        "id": "SYSlFnM6La-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data preprocessing is a fundamental step in dta analysis and machine learning pipelines. It involves transforming raw data into a clean, organized, and suitable format for further analysis or modeling. The primary objectives of data preprocessing are to enhance data quality, resolve inconsistencies, reduce noise, and prepare the data for analysis or modeling tasks.**\n"
      ],
      "metadata": {
        "id": "qqSkimQyLa7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Modeling Approach**\n",
        "\n"
      ],
      "metadata": {
        "id": "-D9RSkLVLa3_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Select the attributes based on which you want to cluster the shows\n",
        "2. Text preprocessing: Remove all non-ascii characters, stopwords and punctuation marks, convert all textual data to lowercase.\n",
        "3. Lemmatization to generate a meaningful word out of corpus of words\n",
        "4. Tokenization of corpus\n",
        "5. Word vectorization\n",
        "6. Dimensionality reduction\n",
        "7. Use different algorithms to cluster the movies, obtain the optimal number of clusters using different techniques\n",
        "8. Build optimal number of clusters and visualize the contents of each cluster using wordclouds.\n"
      ],
      "metadata": {
        "id": "dwESJMRpLaz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will cluster the shows on Netflix based on the following attributes:\n",
        "\n",
        "Director\n",
        "\n",
        "Cast\n",
        "\n",
        "Country\n",
        "\n",
        "Listed in (genres)\n",
        "\n",
        "Description"
      ],
      "metadata": {
        "id": "34_XIB6LLawr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the original dataset for clustering since\n",
        "# it does not require handling missing values\n",
        "df1 = original_df.copy()"
      ],
      "metadata": {
        "id": "5pM5zZMDj9BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.fillna('',inplace=True)"
      ],
      "metadata": {
        "id": "D1A9ZAuWkYne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Combining clustering attributes into a single column***\n"
      ],
      "metadata": {
        "id": "U29w8NcSk3PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = (df1['director'] + ' ' +\n",
        "                                df1['cast'] +' ' +\n",
        "                                df1['country'] +' ' +\n",
        "                                df1['listed_in'] +' ' +\n",
        "                                df1['description'])\n"
      ],
      "metadata": {
        "id": "bqU_YUoVkeF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check wheteher particular row contains all the data\n",
        "df1['clustering_attributes'][40] #prints the values of row 4"
      ],
      "metadata": {
        "id": "yq4HXgZMkdxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ***Removing non-ASCII characters***"
      ],
      "metadata": {
        "id": "VUaDxw-yLatk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ASCII (American Standard Code for Information Interchange). Non-ASCII characters are often represented using different encoding schemes, such as UTF-8 (Unicode Transformation Format 8-bit), which supports a wider range of characters compared to ASCII encoding."
      ],
      "metadata": {
        "id": "r-lfvmQqLap7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove non-ascii characters\n",
        "\n",
        "def remove_non_ascii(words):\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n"
      ],
      "metadata": {
        "id": "yW--uD1XpCBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove non-ascii characters\n",
        "df1['clustering_attributes'] = remove_non_ascii(df1['clustering_attributes'])"
      ],
      "metadata": {
        "id": "DhR0DBDaqtSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "FqdeiuVWpBqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Remove stopwords and convert to lower case:**"
      ],
      "metadata": {
        "id": "YtATdsDlpBfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords are commonly used words in natural language that are often filtered out or ignored during text processing and analysis because they typically do not carry significant meaning or context.\n",
        "\n"
      ],
      "metadata": {
        "id": "OS4f6VrRsPp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the stopwords from nltk library\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "sw = stopwords.words('english')\n",
        "# displaying the stopwords\n",
        "np.array(sw)"
      ],
      "metadata": {
        "id": "4Evkqsr4sMxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove stop words\n",
        "def stopwords(text):\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n"
      ],
      "metadata": {
        "id": "tcjDhx6EpBV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stop words\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(stopwords)\n",
        "df1['clustering_attributes'][40]\n"
      ],
      "metadata": {
        "id": "hv8KueN6uJ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We have successfully removed all the stopwords and converted the corpus to lowercase.***\n",
        "\n"
      ],
      "metadata": {
        "id": "nLpnG0vdpBKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Remove punctuations***\n"
      ],
      "metadata": {
        "id": "HPkroFfSv0lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "D7KoMr-hpA_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation marks\n",
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(remove_punctuation)\n",
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "mzYSzkVFpAm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We have successfully dropped all the punctuation marks from the corpus.***"
      ],
      "metadata": {
        "id": "NBp5QzuDpA1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Lemmatization:**"
      ],
      "metadata": {
        "id": "eU0V2s60pAZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization is often used as a preprocessing step in natural language processing (NLP) tasks to normalize text data. Lemmatization helps reduce words to their base or dictionary form (lemmas), which can improve the performance of ML models by reducing the vocabulary size and capturing the essential meaning of words.\n",
        "\n"
      ],
      "metadata": {
        "id": "oKYpsU-Uznwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the corpus\n",
        "def lemmatize_verbs(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas"
      ],
      "metadata": {
        "id": "VhDN7bY6pAMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "df1['clustering_attributes'] = lemmatize_verbs(df1['clustering_attributes'])\n",
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "mXSpx1WMo_2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***We have lemmatized the corpus***."
      ],
      "metadata": {
        "id": "ijjxSa2-1YYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "hclbrhgjpAAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is the process of breaking down a sequence of text into smaller units, called tokens. These tokens can be words, phrases, symbols, or other meaningful elements, depending on the context and the task at hand.\n",
        "\n"
      ],
      "metadata": {
        "id": "usip6tF42asK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TweetTokenizer()\n"
      ],
      "metadata": {
        "id": "StVTGe8Qo_zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'] = df1['clustering_attributes'].apply(lambda x: tokenizer.tokenize(x))\n"
      ],
      "metadata": {
        "id": "MYjInYviLXgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['clustering_attributes'][40]"
      ],
      "metadata": {
        "id": "dFRANQaB_e5S",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The corpus is converted to tokens.***\n"
      ],
      "metadata": {
        "id": "OrNglw4qo_nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "WfLTFyg8aCe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dff=df1.to_csv('rec_df',index=True)\n"
      ],
      "metadata": {
        "id": "PX7-t45EaCYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vectorization**"
      ],
      "metadata": {
        "id": "CizGs0_d2apK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorization is the process of converting data into numerical vectors or arrays, enabling mathematical operations and analysis. It's a fundamental step in preparing data for machine learning algorithms that typically require numerical input.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ofe5-abbo_OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clustering tokens saved in a variable\n",
        "clustering_data = df1['clustering_attributes']"
      ],
      "metadata": {
        "id": "I789IX0bo_W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def identity_tokenizer(text):\n",
        "    return text"
      ],
      "metadata": {
        "id": "vWD_WNjco-ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using TFIDF vectorizer to vectorize the corpus**"
      ],
      "metadata": {
        "id": "cTbeNwcnAt8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# max features = 20000 to prevent system from crashing\n",
        "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False,max_features = 20000)\n",
        "X = tfidf.fit_transform(clustering_data)"
      ],
      "metadata": {
        "id": "FzpB81MWAtlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "4c49eRExAtF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "cZtSPVV4Btwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data type of vector\n",
        "type(X)\n"
      ],
      "metadata": {
        "id": "t2JNlSBLBttQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X in sparse array into dense array form for clustering\n",
        "X = X.toarray()"
      ],
      "metadata": {
        "id": "-ioPUg9qUhTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dimensionality reduction using PCA**"
      ],
      "metadata": {
        "id": "yESm6ky5DMXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use PCA (Principal component Analysis) to reduce the dimensionality of data.\n",
        "\n"
      ],
      "metadata": {
        "id": "XimbLczJDQ2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using PCA to reduce dimensionality\n",
        "pca = PCA(random_state=42)\n",
        "pca.fit(X) #It will take about 13 min to execute due to larger dataset\n"
      ],
      "metadata": {
        "id": "rQXeogscBtqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Explained variance for different number of components**"
      ],
      "metadata": {
        "id": "0mc0zz8-LH6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.title('PCA - Cumulative explained variance vs number of components')\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance')"
      ],
      "metadata": {
        "id": "mMwj_gs5Zuhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find that 100% of the variance is explained by about ~7500 components.\n",
        "\n",
        "Also, more than 80% of the variance is explained just by 4000 components.\n",
        "\n",
        "Hence to simplify the model, and reduce dimensionality, we can take the top 4000 components, which will still be able to capture more than 80% of variance.\n"
      ],
      "metadata": {
        "id": "EuUM_ZHmAtVy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **reducing the dimensions to 4000 using PCA:**\n"
      ],
      "metadata": {
        "id": "Ulo-FAmZAs1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=4000,random_state=42)\n",
        "pca.fit(X)"
      ],
      "metadata": {
        "id": "cdSaS7xFas-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformed features\n",
        "x_pca = pca.transform(X)\n"
      ],
      "metadata": {
        "id": "UnISVinjzwNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape of transformed vectors\n",
        "x_pca.shape"
      ],
      "metadata": {
        "id": "bITpjjkhz3XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "***We have successfully reduced the dimensionality of data using PCA.***\n"
      ],
      "metadata": {
        "id": "2LU5vZPUzonJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clusters implementation**\n"
      ],
      "metadata": {
        "id": "TGNbZ7Ks1e6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **K-Means Clustering**\n"
      ],
      "metadata": {
        "id": "xNCwMIqO1e29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building clusters using the K-means clustering algorithm.\n",
        "\n",
        "Visualizing the elbow curve and Silhouette score to decide on the optimal number of clusters for K-means clustering algorithm"
      ],
      "metadata": {
        "id": "FTAu9-RS16PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method to find the optimal value of k\n",
        "wcss=[]\n",
        "for i in range(1,31):\n",
        "  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  wcss_iter = kmeans.inertia_\n",
        "  wcss.append(wcss_iter)\n",
        "\n",
        "print(wcss)\n",
        "number_clusters = range(1,31)\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(number_clusters,wcss)\n",
        "plt.title('The Elbow Method - KMeans clustering')\n",
        "plt.xlabel('Number of clusters')\n",
        "plt.ylabel('WCSS')\n"
      ],
      "metadata": {
        "id": "0iT-m2DI3j1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The sum of squared distance between each point and the centroid in a cluster (WCSS) decreases with the increase in the number of clusters.***\n",
        "\n"
      ],
      "metadata": {
        "id": "ig1CybI_16L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Silhouette score for different umber of clusters\n",
        "range_n_clusters = range(2,31)\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:\n",
        "  # initialize kmeans\n",
        "  kmeans = KMeans(n_clusters=num_clusters,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  cluster_labels = kmeans.labels_\n",
        "\n",
        "  # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(x_pca, cluster_labels))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(range_n_clusters,silhouette_avg)\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Silhouette score')\n",
        "plt.title('Silhouette analysis For Optimal k - KMeans clustering')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o_Dm4hmh9iJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***The highest Silhouette score is obtained for 6 clusters.***\n",
        "\n",
        "***Building 6 clusters using the k-means clustering algorith:***\n",
        "\n"
      ],
      "metadata": {
        "id": "aSRm6PehZ4Gc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clustering the data into 6 clusters\n",
        "kmeans = KMeans(n_clusters=6,init='k-means++',random_state=33)\n",
        "kmeans.fit(x_pca)"
      ],
      "metadata": {
        "id": "Y3iRzOtJaq_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics - distortion, Silhouette score\n",
        "kmeans_distortion = kmeans.inertia_\n",
        "kmeans_silhouette_score = silhouette_score(x_pca, kmeans.labels_)\n",
        "\n",
        "print((kmeans_distortion,kmeans_silhouette_score))"
      ],
      "metadata": {
        "id": "ee0-SYsva_iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['kmeans_cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "DekYMLyIbQy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Number of movies and tv shows in each cluster**"
      ],
      "metadata": {
        "id": "DRS4I3afZ4D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='kmeans_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and TV shows in each cluster - Kmeans Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n"
      ],
      "metadata": {
        "id": "8F4WHDBUbX5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Successfully built 6 clusters using the k-means clustering algorithm.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nj6tNMem16Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building wordclouds for different clusters built**\n"
      ],
      "metadata": {
        "id": "fR-F3ZUb16GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def kmeans_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['kmeans_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                   stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "81LMw36ecuXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "kmeans_worldcloud(0)"
      ],
      "metadata": {
        "id": "7cexNJZIc7Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 0: documentary,world,life,history,film,year,family,follow.\n",
        "\n"
      ],
      "metadata": {
        "id": "RX1RYfQmdV1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 1\n",
        "kmeans_worldcloud(1)"
      ],
      "metadata": {
        "id": "rZJakOQThG_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 1:world,adventure,help,new,life,take,family,must,friend."
      ],
      "metadata": {
        "id": "XAK3kmqPdVzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "kmeans_worldcloud(2)"
      ],
      "metadata": {
        "id": "Kjg1_PaIdTWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster:man,find,life,love,family,woman,young."
      ],
      "metadata": {
        "id": "9JZ1zq4VhVYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "kmeans_worldcloud(4)"
      ],
      "metadata": {
        "id": "1UC_40LnhT9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 4:comedy,special,stand,comic,life,show,take,stage,share."
      ],
      "metadata": {
        "id": "glGrLqq2hWaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "kmeans_worldcloud(5)"
      ],
      "metadata": {
        "id": "6DtWeJX-hT7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 5:find, family, new, young, help, two, must, take."
      ],
      "metadata": {
        "id": "oqZsrWWEhZzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Hierarchical clustering**\n"
      ],
      "metadata": {
        "id": "hVDSRevTjANa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building clusters using the agglomerative (hierarchical) clustering algorithm.\n",
        "\n",
        "Visualizing the dendrogram to decide on the optimal number of clusters for the agglomerative (hierarchical) clustering algorithm:"
      ],
      "metadata": {
        "id": "48fej6tEjAFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a dendogram to decide on the number of clusters\n",
        "plt.figure(figsize=(10, 7))\n",
        "dend = shc.dendrogram(shc.linkage(x_pca, method='ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Netflix Shows')\n",
        "plt.ylabel('Distance')\n",
        "plt.axhline(y= 3.8, color='r', linestyle='--')"
      ],
      "metadata": {
        "id": "eaqmBEZRjRq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***At  distance of 3.8 units, 12 clusters can be built using the agglomerative clustering algorithm.***\n"
      ],
      "metadata": {
        "id": "AP6-59eNkxZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Building 12 clusters using the Agglomerative clustering algorithm:**\n",
        "\n"
      ],
      "metadata": {
        "id": "848cokzvkxTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting hierarchical clustering model\n",
        "hierarchical = AgglomerativeClustering(n_clusters=12, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(x_pca)"
      ],
      "metadata": {
        "id": "lWtBs7PXjRk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df1['hierarchical_cluster'] = hierarchical.labels_"
      ],
      "metadata": {
        "id": "RSGLUeGIlY--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of movies and tv shows in each cluster\n",
        "plt.figure(figsize=(10,5))\n",
        "q = sns.countplot(x='hierarchical_cluster',data=df1, hue='type')\n",
        "plt.title('Number of movies and tv shows in each cluster - Hierarchical Clustering')\n",
        "for i in q.patches:\n",
        "  q.annotate(format(i.get_height(), '.0f'), (i.get_x() + i.get_width() / 2., i.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n"
      ],
      "metadata": {
        "id": "3gTN13zqlY5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Successfully built 12 clusters using the Agglomerative (hierarchical) clustering algorithm."
      ],
      "metadata": {
        "id": "pZen-MBkliSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def hierarchical_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df1[df1['hierarchical_cluster']==cluster_num].description.values:\n",
        "\n",
        "      # typecaste each val to string\n",
        "      val = str(val)\n",
        "\n",
        "      # split the value\n",
        "      tokens = val.split()\n",
        "\n",
        "      # Converts each token into lowercase\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,\n",
        "                  background_color ='white',\n",
        "                  stopwords = stopwords,\n",
        "                  min_font_size = 10).generate(comment_words)\n",
        "\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (10,5), facecolor = None)\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad = 0)"
      ],
      "metadata": {
        "id": "mdaz8L42lsX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 0\n",
        "hierarchical_worldcloud(0)"
      ],
      "metadata": {
        "id": "Ynq2MElElsQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster 0:"
      ],
      "metadata": {
        "id": "XqZKPaTvmmQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 1\n",
        "hierarchical_worldcloud(1)"
      ],
      "metadata": {
        "id": "nZ8FsHdnlyah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "DWBDuSDQmAYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 2\n",
        "hierarchical_worldcloud(2)"
      ],
      "metadata": {
        "id": "PdKYgeIIlyUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "y-vyOU3qm196"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 3\n",
        "hierarchical_worldcloud(3)"
      ],
      "metadata": {
        "id": "4eCmKgfjlx5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "Sh8RFAvPmc0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 4\n",
        "hierarchical_worldcloud(4)"
      ],
      "metadata": {
        "id": "Msgfucmclx0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "a4T-m8Dgmdnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 5\n",
        "hierarchical_worldcloud(5)"
      ],
      "metadata": {
        "id": "uH-FbPBrlxk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "hBtWPkECmeJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 6\n",
        "hierarchical_worldcloud(6)"
      ],
      "metadata": {
        "id": "KF94_-Twl6L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "XnPX9faemfMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 7\n",
        "hierarchical_worldcloud(7)"
      ],
      "metadata": {
        "id": "JvoekE_Pl67G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "ZmnRk1iXmgAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 8\n",
        "hierarchical_worldcloud(8)"
      ],
      "metadata": {
        "id": "g6XBWU3Ql7yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "OJrq3nHImguw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 9\n",
        "hierarchical_worldcloud(9)"
      ],
      "metadata": {
        "id": "Nvjk7WNcl6FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y1aOlk9qmh5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 10\n",
        "hierarchical_worldcloud(10)"
      ],
      "metadata": {
        "id": "hR_6uRmbmRzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "FFthm8eimi0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Wordcloud for cluster 11\n",
        "hierarchical_worldcloud(11)"
      ],
      "metadata": {
        "id": "kUl-O-1SmRfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "3o2VHIj1mjX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keywords observed in cluster"
      ],
      "metadata": {
        "id": "KoKt3Mrhmkaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building wordclouds for different clusters built**"
      ],
      "metadata": {
        "id": "MCa4pzb0liL0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Content based recommender system**\n"
      ],
      "metadata": {
        "id": "XobOQpTbjN5-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Content based recommender system\n",
        "We can build a simple content based recommender system based on the similarity of the shows. If a person has watched a show on Netflix, the recommender system must be able to recommend a list of similar shows that s/he likes. To get the similarity score of the shows, we can use cosine similarity The similarity between two vectors (A and B) is calculated by taking the dot product of the two vectors and dividing it by the magnitude value as shown in the equation below. We can simply say that the CS score of two vectors increases as the angle between them decreases."
      ],
      "metadata": {
        "id": "ZsR9-8glhbbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rpGVlNZyrkdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a new df for building a recommender system\n",
        "#rec_df is copy of df1\n",
        "data2='/content/drive/My Drive/rec_df.csv'\n",
        "\n",
        "#Read the data\n",
        "df3=pd.read_csv(data2)\n",
        "recommender_df=df3.copy()\n",
        "recommender_df"
      ],
      "metadata": {
        "id": "RuEAMyOVeQNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the index of the df from show id to show title\n",
        "recommender_df['show_id'] = recommender_df.index"
      ],
      "metadata": {
        "id": "yry5AuZygYuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting tokens to string\n",
        "def convert(lst):\n",
        "  return ' '.join(lst)"
      ],
      "metadata": {
        "id": "_oVnvXwbhQPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recommender_df['clustering_attributes'] = recommender_df['clustering_attributes'].apply(lambda x: convert(x))\n"
      ],
      "metadata": {
        "id": "oObVQWVMhQMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommender_df"
      ],
      "metadata": {
        "id": "KoWvbWnKq6JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting title of movies/Tv shows as index\n",
        "recommender_df.set_index('title',inplace=True)\n"
      ],
      "metadata": {
        "id": "s0uSy94ShQJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommender_df"
      ],
      "metadata": {
        "id": "9fwnKFMmhQHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count Vectorizer**\n",
        "\n",
        "CountVectorizer is a tool in the scikit-learn library used to convert a collection of text documents into a matrix of token counts. It is a popular method for converting textual data into a format that machine learning algorithms can process.\n",
        "\n",
        "CountVectorizer is a tool in the scikit-learn library used to convert a collection of text documents into a matrix of token counts. It is a popular method for converting textual data into a format that machine learning algorithms can process."
      ],
      "metadata": {
        "id": "2SOJfvFJuRgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count vectorizer\n",
        "CV = CountVectorizer()\n",
        "converted_matrix = CV.fit_transform(recommender_df['clustering_attributes'])\n"
      ],
      "metadata": {
        "id": "ODea8mulhQCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cosine similarity:**\n",
        "It is a metric used to measure how similar two vectors are by calculating the cosine of the angle between them. It is widely used in text analysis, recommendation systems, and information retrieval to compare documents or items based on their features.\n",
        "\n",
        "Formula:\n",
        "The formula for cosine similarity between two vectors A and B is:\n",
        "\n",
        "Cosine Similarity\n",
        "=\n",
        "𝐴\n",
        "⋅\n",
        "𝐵\n",
        "/\n",
        "∣∣A∣∣×∣∣B∣∣\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "A⋅B is the dot product of vectors A and B.\n",
        "\n",
        "∣∣A∣∣ and |∣B∣∣ are the magnitudes (or lengths) of vectors A and B.\n",
        "\n",
        "1=similar\n",
        "\n",
        "0=less similar or not"
      ],
      "metadata": {
        "id": "U_wCUYas4a8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine similarity\n",
        "cosine_similarity = cosine_similarity(converted_matrix)\n"
      ],
      "metadata": {
        "id": "ues_kE0Wx9rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity.shape\n"
      ],
      "metadata": {
        "id": "147Nt40vzCNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a function to get 10 recommendations for a show\n",
        "indices = pd.Series(recommender_df.index)\n",
        "\n",
        "def recommend_10(title, cosine_sim = cosine_similarity):\n",
        "  try:\n",
        "    recommend_content = []\n",
        "    idx = indices[indices == title].index[0]\n",
        "    series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "    top10 = list(series.iloc[1:11].index)\n",
        "    # list with the titles of the best 10 matching movies\n",
        "    for i in top10:\n",
        "      recommend_content.append(list(recommender_df.index)[i])\n",
        "    print(\"If you liked '\"+title+\"', you may also enjoy:\\n\")\n",
        "    return recommend_content\n",
        "\n",
        "  except:\n",
        "    return 'Invalid Entry'"
      ],
      "metadata": {
        "id": "ps3gPb6Jx9le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'A Man Called God'\n",
        "recommend_10('A Man Called God')\n"
      ],
      "metadata": {
        "id": "Bl1yDJNP3Jj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Stranger Things'\n",
        "recommend_10('Stranger Things')\n"
      ],
      "metadata": {
        "id": "_vpJs6zL3JeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Peaky Blinders'\n",
        "recommend_10('Peaky Blinders')"
      ],
      "metadata": {
        "id": "YfvvXn9J5sFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'Lucifer'\n",
        "recommend_10('Lucifer')"
      ],
      "metadata": {
        "id": "KGvRflGR5sAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'XXX'\n",
        "recommend_10('xyz')"
      ],
      "metadata": {
        "id": "bvhwo4Fd54RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Invalid because the show 'Xyz' is not available on Netflix."
      ],
      "metadata": {
        "id": "5b61JlEF6AL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Conclusions**"
      ],
      "metadata": {
        "id": "8cBWZNy16ADH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we worked on a text clustering problem wherein we had to classify/group the Netflix shows into certain clusters such that the shows within a cluster are similar to each other and the shows in different clusters are dissimilar to each other.\n",
        "\n",
        "The dataset contained about 7787 records, and 11 attributes. We began by dealing with the dataset's missing values and doing exploratory data analysis (EDA).\n",
        "\n",
        "It was found that Netflix hosts more movies than TV shows on its platform, and the total number of shows added on Netflix is growing exponentially. Also, majority of the shows were produced in the United States, and the majority of the shows on Netflix were created for adults and young adults age group.\n",
        "\n",
        "It was decided to cluster the data based on the attributes: director, cast, country, genre, and description. The values in these attributes were tokenized, preprocessed, and then vectorized using TFIDF vectorizer.\n",
        "\n",
        "Through TFIDF Vectorization, we created a total of 20000 attributes. We used Principal Component Analysis (PCA) to handle the curse of dimensionality. 4000 components were able to capture more than 80% of variance, and hence, the number of components were restricted to 4000.\n",
        "\n",
        "We first built clusters using the k-means clustering algorithm, and the optimal number of clusters came out to be 6. This was obtained through the elbow method and Silhouette score analysis.\n",
        "\n",
        "Then clusters were built using the Agglomerative clustering algorithm, and the optimal number of clusters came out to be 12. This was obtained after visualizing the dendrogram.\n",
        "\n",
        "A content based recommender system was built using the similarity matrix obtained after using cosine similarity. This recommender system will make 10 recommendations to the user based on the type of show they watched."
      ],
      "metadata": {
        "id": "G1ITaI-Y67X4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Successfully completed the project.***"
      ],
      "metadata": {
        "id": "U2h-xKYw7fAV"
      }
    }
  ]
}